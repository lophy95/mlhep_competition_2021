{"backend_state":"running","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-72109ef6-9e85-43ca-b478-7cf9138a010d.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"512e19","input":"","pos":8,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"e47020","input":"","pos":9,"type":"cell"}
{"cell_type":"code","id":"143372","input":"class Print(nn.Module):\n    \"\"\"Debugging only\"\"\"\n\n    def forward(self, x):\n        print(x.size())\n        return x\n\n\nclass Clamp(nn.Module):\n    \"\"\"Clamp energy output\"\"\"\n\n    def forward(self, x):\n        x = torch.clamp(x, min=0, max=30)\n        return x\n\n\nclass SimpleConv(pl.LightningModule):\n    def __init__(self, mode: [\"classification\", \"regression\"] = \"classification\"):\n        super().__init__()\n        self.mode = mode\n        \n        self.layer1 = nn.Sequential(\n                    nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n                    nn.BatchNorm2d(16),\n                    nn.ReLU(),\n                    nn.MaxPool2d(6),\n                    nn.Conv2d(16,32,4,stride=1,padding=1),\n                    nn.BatchNorm2d(32),\n                    nn.ReLU(),\n                    nn.MaxPool2d(kernel_size=6,stride=3),\n                    nn.Flatten(),\n                )\n        \n        \n        #self.layer1 = nn.Sequential(\n        #            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n        #            nn.BatchNorm2d(16),\n        #            nn.ReLU(),\n        #            nn.MaxPool2d(kernel_size=19, stride=7),\n        #            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n        #            nn.BatchNorm2d(32),\n        #            nn.ReLU(),\n        #            nn.MaxPool2d(kernel_size=3,stride=3),\n        #            nn.Flatten(),\n        #        )\n        \n\n\n        self.drop_out = nn.Dropout(p=0.4)\n\n        self.fc1 = nn.Linear(800,200) \n        self.fc2 = nn.Linear(200, 2)  # for classification\n        self.fc3 = nn.Linear(200, 1)  # for regression\n        #self.fc4 = nn.Linear(400,1) # changed by me\n\n        self.stem = nn.Sequential(\n            self.layer1, self.drop_out, self.fc1,\n            )\n        if self.mode == \"classification\":\n            self.classification = nn.Sequential(self.stem, self.fc2)\n        else:\n            self.regression = nn.Sequential(self.stem, self.fc3)\n\n        self.train_acc = pl.metrics.Accuracy()\n        self.valid_acc = pl.metrics.Accuracy()\n        self.test_acc = pl.metrics.Accuracy()\n\n    def training_step(self, batch, batch_idx):\n        # --------------------------\n        x_target, class_target, reg_target, _ = batch\n        if self.mode == \"classification\":\n            class_pred = self.classification(x_target.float())\n            class_loss = F.binary_cross_entropy_with_logits(\n                class_pred, class_target.float()\n            )\n            self.train_acc(torch.sigmoid(class_pred), class_target)\n            self.log(\"train_acc\", self.train_acc, on_step=True, on_epoch=False)\n            self.log(\"classification_loss\", class_loss)\n\n            return class_loss\n\n        else:\n            reg_pred = self.regression(x_target.float())\n            #             reg_loss = F.l1_loss(reg_pred, reg_target.float().view(-1, 1))\n            reg_loss = F.mse_loss(reg_pred, reg_target.float().view(-1, 1))\n\n            #             reg_loss = torch.sum(torch.abs(reg_pred - reg_target.float().view(-1, 1)) / reg_target.float().view(-1, 1))\n            self.log(\"regression_loss\", reg_loss)\n            return reg_loss\n\n    def training_epoch_end(self, outs):\n        # log epoch metric\n        if self.mode == \"classification\":\n            self.log(\"train_acc_epoch\", self.train_acc.compute())\n        else:\n            pass\n\n    def validation_step(self, batch, batch_idx):\n        x_target, class_target, reg_target, _ = batch\n        if self.mode == \"classification\":\n            class_pred = self.classification(x_target.float())\n            class_loss = F.binary_cross_entropy_with_logits(\n                class_pred, class_target.float()\n            )\n            self.valid_acc(torch.sigmoid(class_pred), class_target)\n            self.log(\"valid_acc\", self.valid_acc.compute())\n            self.log(\"classification_loss\", class_loss)\n            return class_loss\n\n        else:\n            reg_pred = self.regression(x_target.float())\n            #             reg_loss = F.l1_loss(reg_pred, reg_target.float().view(-1, 1))\n            reg_loss = F.mse_loss(reg_pred, reg_target.float().view(-1, 1))\n\n            #             reg_loss = torch.sum(torch.abs(reg_pred - reg_target.float().view(-1, 1)) / reg_target.float().view(-1, 1))\n            self.log(\"regression_loss\", reg_loss)\n            return reg_loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adamax(self.parameters(), lr=1e-3)\n        return optimizer\n\n    def forward(self, x):\n        if self.mode == \"classification\":\n            class_pred = self.classification(x.float())\n            return {\"class\": torch.sigmoid(class_pred)}\n        else:\n            reg_pred = self.regression(x.float())\n            return {\"energy\": reg_pred}\n","pos":3,"type":"cell"}
{"cell_type":"code","id":"411f67","input":"DM_model = SimpleConv()","pos":4,"type":"cell"}
{"cell_type":"code","id":"456875","input":"from torchinfo import summary\nsummary(DM_model, input_size=(1,1,120,120))","pos":5,"type":"cell"}
{"cell_type":"code","id":"72fe6e","input":"class IDAODataset(DatasetFolder):\n    def name_to_energy(self, name):\n        names = os.path.split(name)[-1].split(\"_\")\n        idx = [i for i, v in enumerate(names) if v == \"keV\"][0]\n        return torch.tensor(float(names[idx - 1]))\n\n    def name_to_index(self, name):\n        return os.path.split(name)[-1].split('.')[0]\n\n    def __getitem__(self, index: int):\n        path, target = self.samples[index]\n        sample = self.loader(path)\n        if self.transform is not None:\n            sample = self.transform(sample)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return sample, target, self.name_to_energy(path), self.name_to_index(path)\n\nclass InferenceDataset(Dataset):\n    def __init__(self, main_dir, transform, loader=None):\n        self.img_loaderj= img_loader\n        self.main_dir = path.Path(main_dir)\n        self.transform = transform\n        self.all_imgs = list(self.main_dir.glob(\"*.png\"))\n        self.loader = loader\n\n    def __len__(self):\n        return len(self.all_imgs)\n\n    def __getitem__(self, idx):\n        img_loc = self.all_imgs[idx]\n        image = self.loader(img_loc)\n        tensor_image = self.transform(image)\n        return tensor_image, img_loc.name\n\ndef img_loader(path: str):\n    with Image.open(path) as img:\n        img = np.array(img)\n    return img\n","pos":1,"type":"cell"}
{"cell_type":"code","id":"8017ed","input":"def trainer(mode: [\"classification\", \"regression\"], cfg, dataset_dm):\n    model = SimpleConv(mode=mode)\n    if mode == \"classification\":\n        epochs = cfg[\"TRAINING\"][\"ClassificationEpochs\"]\n    else:\n        epochs = cfg[\"TRAINING\"][\"RegressionEpochs\"]\n    trainer = pl.Trainer(\n        gpus=int(cfg[\"TRAINING\"][\"NumGPUs\"]),\n        max_epochs=int(epochs),\n        progress_bar_refresh_rate=20,\n        weights_save_path=path.Path(cfg[\"TRAINING\"][\"ModelParamsSavePath\"]).joinpath(\n            mode\n        ),\n        default_root_dir=path.Path(cfg[\"TRAINING\"][\"ModelParamsSavePath\"]),\n    )\n\n    # Train the model âš¡\n    trainer.fit(model, dataset_dm)\n\n\ndef main():\n    seed_everything(666)\n    config = configparser.ConfigParser()\n    config.read(\"./config.ini\")\n\n    PATH = path.Path(config[\"DATA\"][\"DatasetPath\"])\n\n    dataset_dm = IDAODataModule(\n        data_dir=PATH, batch_size=int(config[\"TRAINING\"][\"BatchSize\"]), cfg=config\n    )\n    dataset_dm.prepare_data()\n    dataset_dm.setup()\n\n\n    for mode in [\"classification\", \"regression\"]:\n        print(f\"Training for {mode}\")\n        trainer(mode, cfg=config, dataset_dm=dataset_dm)\n","pos":6,"type":"cell"}
{"cell_type":"code","id":"cc22d7","input":"class IDAODataModule(pl.LightningDataModule):\n    def __init__(self, data_dir: path.Path, batch_size: int, cfg):\n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.cfg = cfg\n\n    def prepare_data(self):\n        # called only on 1 GPU\n        self.dataset = IDAODataset(\n            root=self.data_dir.joinpath(\"train\"),\n            loader=img_loader,\n            transform=transforms.Compose(\n                [transforms.ToTensor(), transforms.CenterCrop(120)]  #CenterCrop(120)\n            ),\n            # TODO(kazeevn) use idiomatic torch\n            target_transform=transforms.Compose(\n                [\n                    lambda num: (\n                        torch.tensor([0, 1]) if num == 0 else torch.tensor([1, 0])\n                    )\n                ]\n            ),\n            extensions=self.cfg[\"DATA\"][\"Extension\"],\n        )\n\n        self.test = InferenceDataset(\n                    main_dir=self.data_dir.joinpath(\"test\"),\n                    loader=img_loader,\n                    transform=transforms.Compose(\n                        [transforms.ToTensor(), transforms.CenterCrop(120)]#CenterCrop(120)\n                    ),\n                )\n\n\n    def setup(self, stage=None):\n        # called on every GPU\n        self.train, self.val = random_split(\n            self.dataset, [10000, 3404], generator=torch.Generator().manual_seed(666)\n        )\n\n    def train_dataloader(self):\n        return DataLoader(self.train, self.batch_size, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val, 1, num_workers=3, shuffle=False)\n    \n    def test_dataloader(self):\n        return DataLoader(\n            self.test,\n            self.batch_size,\n            num_workers=0,\n            shuffle=False\n            )\n\n","pos":2,"type":"cell"}
{"cell_type":"code","id":"e6748d","input":"import configparser\nimport pathlib as path\nimport pytorch_lightning as pl\nfrom pytorch_lightning import seed_everything\nfrom idao.data_module import IDAODataModule\nfrom idao.model import SimpleConv\nimport numpy as np\nimport torch\nimport os\nimport pathlib as path\nfrom PIL import Image\nfrom torchvision.datasets import DatasetFolder\nfrom torch.utils.data import Dataset\nimport pathlib as path\n\nimport pytorch_lightning as pl\nimport torch\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nimport configparser\nimport pathlib as path\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import seed_everything\n\n","pos":0,"type":"cell"}
{"cell_type":"code","id":"f87385","input":"if __name__ == \"__main__\":\n    main()","pos":7,"scrolled":true,"type":"cell"}
{"id":0,"time":1627559055484,"type":"user"}
{"last_load":1627559052728,"type":"file"}