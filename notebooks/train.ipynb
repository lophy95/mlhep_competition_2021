{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import configparser\n",
    "import pathlib as path\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from idao.data_module import IDAODataModule\n",
    "from idao.model import SimpleConv\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pathlib as path\n",
    "from PIL import Image\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.utils.data import Dataset\n",
    "import pathlib as path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import configparser\n",
    "import pathlib as path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "class IDAODataset(DatasetFolder):\n",
    "    def name_to_energy(self, name):\n",
    "        names = os.path.split(name)[-1].split(\"_\")\n",
    "        idx = [i for i, v in enumerate(names) if v == \"keV\"][0]\n",
    "        return torch.tensor(float(names[idx - 1]))\n",
    "\n",
    "    def name_to_index(self, name):\n",
    "        return os.path.split(name)[-1].split('.')[0]\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target, self.name_to_energy(path), self.name_to_index(path)\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, main_dir, transform, loader=None):\n",
    "        self.img_loaderj= img_loader\n",
    "        self.main_dir = path.Path(main_dir)\n",
    "        self.transform = transform\n",
    "        self.all_imgs = list(self.main_dir.glob(\"*.png\"))\n",
    "        self.loader = loader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = self.all_imgs[idx]\n",
    "        image = self.loader(img_loc)\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image, img_loc.name\n",
    "\n",
    "def img_loader(path: str):\n",
    "    with Image.open(path) as img:\n",
    "        img = np.array(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "class IDAODataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: path.Path, batch_size: int, cfg):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # called only on 1 GPU\n",
    "        self.dataset = IDAODataset(\n",
    "            root=self.data_dir.joinpath(\"train\"),\n",
    "            loader=img_loader,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.CenterCrop(120)]  #CenterCrop(120)\n",
    "            ),\n",
    "            # TODO(kazeevn) use idiomatic torch\n",
    "            target_transform=transforms.Compose(\n",
    "                [\n",
    "                    lambda num: (\n",
    "                        torch.tensor([0, 1]) if num == 0 else torch.tensor([1, 0])\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            extensions=self.cfg[\"DATA\"][\"Extension\"],\n",
    "        )\n",
    "\n",
    "        self.test = InferenceDataset(\n",
    "                    main_dir=self.data_dir.joinpath(\"test\"),\n",
    "                    loader=img_loader,\n",
    "                    transform=transforms.Compose(\n",
    "                        [transforms.ToTensor(), transforms.CenterCrop(120)]#CenterCrop(120)\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # called on every GPU\n",
    "        self.train, self.val = random_split(\n",
    "            self.dataset, [10000, 3404], generator=torch.Generator().manual_seed(666)\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, 1, num_workers=3, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test,\n",
    "            self.batch_size,\n",
    "            num_workers=0,\n",
    "            shuffle=False\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "class Print(nn.Module):\n",
    "    \"\"\"Debugging only\"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        return x\n",
    "\n",
    "\n",
    "class Clamp(nn.Module):\n",
    "    \"\"\"Clamp energy output\"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(x, min=0, max=30)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleConv(pl.LightningModule):\n",
    "    def __init__(self, mode: [\"classification\", \"regression\"] = \"classification\"):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "                    nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "                    nn.BatchNorm2d(16),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(6),\n",
    "                    nn.Conv2d(16,32,4,stride=1,padding=1),\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=6,stride=3),\n",
    "                    nn.Flatten(),\n",
    "                )\n",
    "        \n",
    "        \n",
    "        #self.layer1 = nn.Sequential(\n",
    "        #            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "        #            nn.BatchNorm2d(16),\n",
    "        #            nn.ReLU(),\n",
    "        #            nn.MaxPool2d(kernel_size=19, stride=7),\n",
    "        #            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "        #            nn.BatchNorm2d(32),\n",
    "        #            nn.ReLU(),\n",
    "        #            nn.MaxPool2d(kernel_size=3,stride=3),\n",
    "        #            nn.Flatten(),\n",
    "        #        )\n",
    "        \n",
    "\n",
    "\n",
    "        self.drop_out = nn.Dropout(p=0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(800,200) \n",
    "        self.fc2 = nn.Linear(200, 2)  # for classification\n",
    "        self.fc3 = nn.Linear(200, 1)  # for regression\n",
    "        #self.fc4 = nn.Linear(400,1) # changed by me\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            self.layer1, self.drop_out, self.fc1,\n",
    "            )\n",
    "        if self.mode == \"classification\":\n",
    "            self.classification = nn.Sequential(self.stem, self.fc2)\n",
    "        else:\n",
    "            self.regression = nn.Sequential(self.stem, self.fc3)\n",
    "\n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # --------------------------\n",
    "        x_target, class_target, reg_target, _ = batch\n",
    "        if self.mode == \"classification\":\n",
    "            class_pred = self.classification(x_target.float())\n",
    "            class_loss = F.binary_cross_entropy_with_logits(\n",
    "                class_pred, class_target.float()\n",
    "            )\n",
    "            self.train_acc(torch.sigmoid(class_pred), class_target)\n",
    "            self.log(\"train_acc\", self.train_acc, on_step=True, on_epoch=False)\n",
    "            self.log(\"classification_loss\", class_loss)\n",
    "\n",
    "            return class_loss\n",
    "\n",
    "        else:\n",
    "            reg_pred = self.regression(x_target.float())\n",
    "            #             reg_loss = F.l1_loss(reg_pred, reg_target.float().view(-1, 1))\n",
    "            reg_loss = F.mse_loss(reg_pred, reg_target.float().view(-1, 1))\n",
    "\n",
    "            #             reg_loss = torch.sum(torch.abs(reg_pred - reg_target.float().view(-1, 1)) / reg_target.float().view(-1, 1))\n",
    "            self.log(\"regression_loss\", reg_loss)\n",
    "            return reg_loss\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        if self.mode == \"classification\":\n",
    "            self.log(\"train_acc_epoch\", self.train_acc.compute())\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_target, class_target, reg_target, _ = batch\n",
    "        if self.mode == \"classification\":\n",
    "            class_pred = self.classification(x_target.float())\n",
    "            class_loss = F.binary_cross_entropy_with_logits(\n",
    "                class_pred, class_target.float()\n",
    "            )\n",
    "            self.valid_acc(torch.sigmoid(class_pred), class_target)\n",
    "            self.log(\"valid_acc\", self.valid_acc.compute())\n",
    "            self.log(\"classification_loss\", class_loss)\n",
    "            return class_loss\n",
    "\n",
    "        else:\n",
    "            reg_pred = self.regression(x_target.float())\n",
    "            #             reg_loss = F.l1_loss(reg_pred, reg_target.float().view(-1, 1))\n",
    "            reg_loss = F.mse_loss(reg_pred, reg_target.float().view(-1, 1))\n",
    "\n",
    "            #             reg_loss = torch.sum(torch.abs(reg_pred - reg_target.float().view(-1, 1)) / reg_target.float().view(-1, 1))\n",
    "            self.log(\"regression_loss\", reg_loss)\n",
    "            return reg_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adamax(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == \"classification\":\n",
    "            class_pred = self.classification(x.float())\n",
    "            return {\"class\": torch.sigmoid(class_pred)}\n",
    "        else:\n",
    "            reg_pred = self.regression(x.float())\n",
    "            return {\"energy\": reg_pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "DM_model = SimpleConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(DM_model, input_size=(1,1,120,120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def trainer(mode: [\"classification\", \"regression\"], cfg, dataset_dm):\n",
    "    model = SimpleConv(mode=mode)\n",
    "    if mode == \"classification\":\n",
    "        epochs = cfg[\"TRAINING\"][\"ClassificationEpochs\"]\n",
    "    else:\n",
    "        epochs = cfg[\"TRAINING\"][\"RegressionEpochs\"]\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=int(cfg[\"TRAINING\"][\"NumGPUs\"]),\n",
    "        max_epochs=int(epochs),\n",
    "        progress_bar_refresh_rate=20,\n",
    "        weights_save_path=path.Path(cfg[\"TRAINING\"][\"ModelParamsSavePath\"]).joinpath(\n",
    "            mode\n",
    "        ),\n",
    "        default_root_dir=path.Path(cfg[\"TRAINING\"][\"ModelParamsSavePath\"]),\n",
    "    )\n",
    "\n",
    "    # Train the model âš¡\n",
    "    trainer.fit(model, dataset_dm)\n",
    "\n",
    "\n",
    "def main():\n",
    "    seed_everything(666)\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"./config.ini\")\n",
    "\n",
    "    PATH = path.Path(config[\"DATA\"][\"DatasetPath\"])\n",
    "\n",
    "    dataset_dm = IDAODataModule(\n",
    "        data_dir=PATH, batch_size=int(config[\"TRAINING\"][\"BatchSize\"]), cfg=config\n",
    "    )\n",
    "    dataset_dm.prepare_data()\n",
    "    dataset_dm.setup()\n",
    "\n",
    "\n",
    "    for mode in [\"classification\", \"regression\"]:\n",
    "        print(f\"Training for {mode}\")\n",
    "        trainer(mode, cfg=config, dataset_dm=dataset_dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3",
   "resource_dir": "/usr/local/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}